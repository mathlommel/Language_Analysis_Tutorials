{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Delivery nÂ°5 : Topic Modelling\n",
        "\n",
        "*Mathematics and Big Data - Mathias Lommel*"
      ],
      "metadata": {
        "id": "K5VmFQ4wsMmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this 5th delivery, we will apply the topic modelling notions seen in class on Quora Questions & answers, using different packages of Python, such as NTLK."
      ],
      "metadata": {
        "id": "pU6Y6acPfBe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library importations\n",
        "\n",
        "As always, we have to import fiew libraries that will be important for our work."
      ],
      "metadata": {
        "id": "rhCGDff0suHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffw4ncHEqWRQ",
        "outputId": "a191adb3-406d-4d66-9f36-c8a8512b0220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "import string\n",
        "import re\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition of the functions\n",
        "\n",
        "Now, let's define the functions that we will use to solve our problem."
      ],
      "metadata": {
        "id": "rXYt2FqAtRuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading file\n",
        "\n",
        "Again, I made this delivery on Google Colab. Then, I have created 2 different codes that can be used to read the .csv file."
      ],
      "metadata": {
        "id": "tfGt3dYi8ACZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using google Colab\n",
        "def open_document_with_Drive(path):\n",
        "  \"\"\"\n",
        "  This function read a csv file from Drive.\n",
        "\n",
        "    Input :\n",
        "        path : string - path of the file\n",
        "    Output :\n",
        "       data  : pd.DataFrame - extracted data\n",
        "  \"\"\"\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  data = pd.read_csv(path)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "UH1LKL2EtVpb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the document is stored locally on the computer\n",
        "def open_document(path):\n",
        "  \"\"\"\n",
        "  This function read a csv file stored locally.\n",
        "\n",
        "    Input :\n",
        "        path : string - path of the file\n",
        "    Output :\n",
        "        data  : pd.DataFrame - extracted data\n",
        "  \"\"\"\n",
        "  data = pd.read_csv(path)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "0-73plJCwACi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing\n",
        "\n",
        "As we have done in the previous deliveries, we have to pre-process our data.\n",
        "\n",
        "Here, we will re-use the functions defined for the 4th delivery. In other words, we create 2 functions, one to preprocess one question (one line of the dataframe), and another one, that uses this first function to preprocess the whole database."
      ],
      "metadata": {
        "id": "vp-0XqmIAQxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that cleans the data\n",
        "def preprocess_line(data):\n",
        "  \"\"\"\n",
        "  This function preprocess a text.\n",
        "\n",
        "    Input :\n",
        "        review : string - question to preprocess\n",
        "    Output :\n",
        "        review : string - preprocessed question\n",
        "  \"\"\"\n",
        "  # Change to lower case\n",
        "  data = data.lower()\n",
        "\n",
        "  # Remove URLs (http and https)\n",
        "  data = re.sub(\"http?:\\/\\/.*[\\r\\n]*\", \"\", data)\n",
        "  data = re.sub(\"https?:\\/\\/.*[\\r\\n]*\", \"\", data)\n",
        "\n",
        "  # Remove emails\n",
        "  data = re.sub(r'\\b[A-Za-z0-9._-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b','',data)\n",
        "\n",
        "  # Remove mentions\n",
        "  data = re.sub(\"@\\S+\", \"\", data)\n",
        "\n",
        "  # Remove punctuations, commas and special characters\n",
        "  punctuation = string.punctuation\n",
        "  translation_table = str.maketrans('', '', punctuation)\n",
        "\n",
        "  data = data.translate(translation_table)\n",
        "\n",
        "  # Remove numbers\n",
        "  data = re.sub(r'\\d+', '', data)\n",
        "\n",
        "  return data\n",
        "\n",
        "def preprocess_data(data):\n",
        "  \"\"\"\n",
        "  This function preprocess the whole database.\n",
        "\n",
        "    Input :\n",
        "        data          : pd.DataFrame - database to preprocess\n",
        "    Output :\n",
        "        cleaned_data  : pd.DataFrame - preprocessed database\n",
        "  \"\"\"\n",
        "  # We apply the preprocessing function to each review\n",
        "  cleaned_reviews = data['Question'].apply(preprocess_line)\n",
        "\n",
        "  # We build a new dataframe, with preprocessed reviews\n",
        "  cleaned_data = pd.DataFrame({'Question' : cleaned_reviews})\n",
        "\n",
        "  print(\"Pre-processing successfully computed.\")\n",
        "\n",
        "  return cleaned_data\n"
      ],
      "metadata": {
        "id": "91eUs3O2zQqx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application of our functions\n",
        "\n",
        "Now, we are going to apply our functions on the dataset of study, in order to try to solve Quora's problems."
      ],
      "metadata": {
        "id": "Nb7jSzeEwnoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading of the file"
      ],
      "metadata": {
        "id": "mdtLq4jMJXxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading of the file\n",
        "## With Google Colab\n",
        "path = '/content/drive/My Drive/quora.csv'\n",
        "data = open_document_with_Drive(path)\n",
        "\n",
        "## Without Colab\n",
        "#path = \"path/of/the/file\"\n",
        "#data = open_document(path)\n",
        "\n",
        "# Let's have a look at the dataframe created : quite simple, with only one column (the questions)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "KjvjiWxows2L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c2a1aa07-922d-4b75-e233-576fa050777b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Question\n",
              "0  What is the step by step guide to invest in sh...\n",
              "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
              "2  How can I increase the speed of my internet co...\n",
              "3  Why am I mentally very lonely? How can I solve...\n",
              "4  Which one dissolve in water quikly sugar, salt..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-447c894d-c11d-4638-b0ad-47ecb3717d8f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-447c894d-c11d-4638-b0ad-47ecb3717d8f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-447c894d-c11d-4638-b0ad-47ecb3717d8f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-447c894d-c11d-4638-b0ad-47ecb3717d8f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc798837-adeb-4fd2-bbe4-b1c81283ef01\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc798837-adeb-4fd2-bbe4-b1c81283ef01')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc798837-adeb-4fd2-bbe4-b1c81283ef01 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then find quite easily the number of questions asked in the database."
      ],
      "metadata": {
        "id": "ODFCG7O7BCsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"There are\", len(data), \"questions asked in this database.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvxl3tXylDA9",
        "outputId": "ebc25a08-afda-48ca-e4d5-6a3ac9f66c43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 404289 questions asked in this database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing\n",
        "\n",
        "Here, we will apply our preprocessing function to the created dataframe."
      ],
      "metadata": {
        "id": "CA6qsgidBKR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data = preprocess_data(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia2uWLb1nq8e",
        "outputId": "86d45f21-19db-4524-a3d3-9dbe6287043a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing successfully computed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Document Term Matrix\n",
        "\n",
        "We can now, count the number of different words in the entire database.\n",
        "\n",
        "This number gives us the number of columns of the Document Term Matrix"
      ],
      "metadata": {
        "id": "FM9VDEQABvAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We concatenate the questions, and we convert it into a set (to avoid repetitions)\n",
        "unique_words = set(' '.join(cleaned_data['Question']).split())\n",
        "\n",
        "# We then convert it into a list, for convenience\n",
        "unique_words = list(unique_words)\n",
        "print(\"There are\",len(unique_words),\"unique terms in the entire database.\")\n",
        "print(\"Then, the dimension of the Document Term Matrix should be\",len(data),\"x\",len(unique_words),\".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw4Nxv_2lOTl",
        "outputId": "f259df1d-2fb6-479c-db18-bbdd95e5aaa4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 76719 unique terms in the entire database.\n",
            "Then, the dimension of the Document Term Matrix should be 404289 x 76719 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is interesting here is that, among the hundred of thousand of words in the database, most of them are often repeated from question to question. Then, we obtain less than 80 000 unique words.\n",
        "\n",
        "To reassure ourselves, we can print the first 30 words of the list, in order to verify that the words are not repeated."
      ],
      "metadata": {
        "id": "0EV5J-a0o6V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(unique_words[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VQ3p9BqmSTu",
        "outputId": "b30f4210-ad03-4cd4-e639-732efe5958fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['overthrown', 'slinky', 'fbis', 'cpubound', 'trinkt', 'energyintensive', 'glider', 'tonk', 'injection', 'colou', 'timesthen', 'à¤µà¤¹', 'ingest', 'sructure', 'bjÃ¶rling', 'mourinho', 'belog', 'monastery', 'codenvy', 'unreadable', 'mieghem', 'davos', 'shloka', 'seethrough', 'ryerson', 'pilaris', 'laps', 'atlas', 'opiates', 'xwing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see with this little check, we don't see any repeated word, so we can be more confident in what we have done."
      ],
      "metadata": {
        "id": "QozYMGTFpoyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now, we can compute the Document Term Matrix."
      ],
      "metadata": {
        "id": "OP7EVXEihs8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use TF-IDF Vectorization to create a vectorized document term matrix\n",
        "cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "dtm = cv.fit_transform(cleaned_data['Question'])"
      ],
      "metadata": {
        "id": "_D6AqDcDqT8G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The shape of the document term matrix is :\", dtm.shape[0],\"x\",dtm.shape[1],\".\")"
      ],
      "metadata": {
        "id": "kssrRkNUFh6M",
        "outputId": "113f1f0a-222b-4903-fb1d-f6dbb6d479ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the document term matrix is : 404289 x 39679 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the dimension of the document term matrix is quite different from what we have expected. This is just because during this process, we have deleted the english stop words, which decrease the number of columns of the matrix.\n",
        "\n",
        "This observation shows us that this operaton is quite interesting, since we have almost divided by 2 the number of columns of the matrix."
      ],
      "metadata": {
        "id": "wBITYv19Fomv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Number of words for each document\n",
        "\n",
        "Now, using the Document Term Matrix, we can find the number of words for each question of our database."
      ],
      "metadata": {
        "id": "ZFokXLsFGgLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We determine the words present for each document\n",
        "tab = dtm > 0\n",
        "# We initialize our result\n",
        "number_words = np.zeros((len(cleaned_data),1))\n",
        "\n",
        "# For each document, we compute the number of 1\n",
        "for i in range(len(cleaned_data)):\n",
        "  number_words[i] = tab[tab[i]].shape[1]\n",
        "\n",
        "# Show the result\n",
        "number_words_per_document = pd.DataFrame({'Number of words':number_words[:,0]})\n",
        "print(\"Number of words for each document : \")\n",
        "print(number_words_per_document)"
      ],
      "metadata": {
        "id": "7ThTm_forgiv",
        "outputId": "a149f0d6-5f0b-453e-ecd6-a8a4c77386f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words for each document : \n",
            "        Number of words\n",
            "0                   6.0\n",
            "1                   3.0\n",
            "2                   6.0\n",
            "3                   3.0\n",
            "4                   9.0\n",
            "...                 ...\n",
            "404284              6.0\n",
            "404285              3.0\n",
            "404286              1.0\n",
            "404287              9.0\n",
            "404288              3.0\n",
            "\n",
            "[404289 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Topic modelling\n",
        "\n",
        "Now, from our data, we can extract the topics they are about.\n",
        "\n",
        "Here, we will use the *Latent Dirichlet Allocation*. This method builds a topic per document and words per topic model, modeled as Dirichlet distributions."
      ],
      "metadata": {
        "id": "W8AJTSfhIepB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We apply the LDA model\n",
        "LDA = LatentDirichletAllocation(n_components=7,random_state=42)\n",
        "LDA.fit(dtm)"
      ],
      "metadata": {
        "id": "umERlz52xZdd",
        "outputId": "d1fb3fc5-a11c-4876-bba1-8322313046cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=7, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=7, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=7, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"From the database of study, we have extracted\",LDA.components_.shape[0],\"different topics.\")"
      ],
      "metadata": {
        "id": "e46g8F3YJEAc",
        "outputId": "a34aaf04-d19a-4866-bdb8-d9e33a71de29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From the database of study, we have extracted 7 different topics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, for each topic, we can determine the 10 most common words. This step will help us to understand what the different topics are about."
      ],
      "metadata": {
        "id": "UP8bdcq1cZLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index,topic in enumerate(LDA.components_):\n",
        "    print(f'THE TOP 10 WORDS FOR TOPIC #{index}')\n",
        "    names = cv.get_feature_names_out()\n",
        "    print([names[i] for i in topic.argsort()[-10:]])\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "FrUiRtF80yRR",
        "outputId": "2db8685f-15ae-4785-b9ba-1076e292bbe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE TOP 10 WORDS FOR TOPIC #0\n",
            "['free', 'buy', 'used', 'android', 'movies', 'facebook', 'number', 'use', 'phone', 'best']\n",
            "\n",
            "\n",
            "THE TOP 10 WORDS FOR TOPIC #1\n",
            "['war', 'does', 'question', 'donald', 'notes', 'questions', 'people', 'trump', 'world', 'quora']\n",
            "\n",
            "\n",
            "THE TOP 10 WORDS FOR TOPIC #2\n",
            "['read', 'difference', 'india', 'think', 'books', 'things', 'life', 'know', 'does', 'people']\n",
            "\n",
            "\n",
            "THE TOP 10 WORDS FOR TOPIC #3\n",
            "['learn', 'google', 'does', 'account', 'iphone', 'examples', 'instagram', 'improve', 'english', 'difference']\n",
            "\n",
            "\n",
            "THE TOP 10 WORDS FOR TOPIC #4\n",
            "['business', 'thing', 'engineering', 'good', 'india', 'job', 'learn', 'start', 'way', 'best']\n",
            "\n",
            "\n",
            "THE TOP 10 WORDS FOR TOPIC #5\n",
            "['women', 'im', 'time', 'sex', 'girl', 'love', 'feel', 'best', 'does', 'like']\n",
            "\n",
            "\n",
            "THE TOP 10 WORDS FOR TOPIC #6\n",
            "['lose', 'ways', 'weight', 'mean', 'online', 'best', 'india', 'money', 'make', 'does']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapping with the questions\n",
        "\n",
        "Now, we can use the LDA model to map each question to the right topic.\n",
        "\n",
        "To do that, we will make a dataframe, containing 3 columns :\n",
        "  - The document number\n",
        "  - The list of its main topics : the ones with a probability greater than 0.1\n",
        "  - The number of topics associated with the document\n",
        "  - Its main topic : the one with the highest probability"
      ],
      "metadata": {
        "id": "fpBkvLXXcpiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linking the topics and documents\n",
        "topic_results = LDA.transform(dtm)"
      ],
      "metadata": {
        "id": "cDOuHDfe2m8J"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_main_topic = np.zeros((len(cleaned_data),1),dtype=int)\n",
        "document_topics = []\n",
        "document_nb_topics = []\n",
        "document = np.linspace(1,len(cleaned_data),len(cleaned_data),dtype=int)\n",
        "\n",
        "for i in range(len(cleaned_data)):\n",
        "  document_topics.append(np.where(np.array(topic_results[i])>0.1))\n",
        "  document_nb_topics.append(sum(np.array(topic_results[i])>0.1))\n",
        "  document_main_topic[i] = topic_results[i].argmax()\n",
        "\n",
        "link_topics = pd.DataFrame({'Document':document,'Topics': document_topics,'Nb Topics':document_nb_topics,'Main topic':document_main_topic[:,0]})\n",
        "print(link_topics)"
      ],
      "metadata": {
        "id": "ymMGYwjU3ZqN",
        "outputId": "337a7e03-be1d-47a9-d58b-af892834e256",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Document              Topics  Nb Topics  Main topic\n",
            "0              1        ([1, 3, 4],)          3           4\n",
            "1              2              ([0],)          1           0\n",
            "2              3           ([0, 5],)          2           0\n",
            "3              4        ([1, 4, 5],)          3           4\n",
            "4              5           ([0, 6],)          2           0\n",
            "...          ...                 ...        ...         ...\n",
            "404284    404285              ([4],)          1           4\n",
            "404285    404286              ([2],)          1           2\n",
            "404286    404287              ([5],)          1           5\n",
            "404287    404288  ([1, 3, 4, 5, 6],)          5           4\n",
            "404288    404289              ([5],)          1           5\n",
            "\n",
            "[404289 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interesting topics\n",
        "\n",
        "Then, we can also determine the topic people are mostly interested in, and the least interesting one, considering that an interesting topic is mentioned in many questions.\n",
        "\n",
        "$\\to$ We are searching for the most recurrent topic, and the least frequent one.\n"
      ],
      "metadata": {
        "id": "CCb8b2jydM3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To answer this problem, we will use 2 different approaches.\n",
        "\n",
        "$\\to$ We can, for example, for each topic, add the probabilities, among all the documents. Then, we select the topic with the max/min sum of probabilities.\n",
        "\n",
        "$\\to$ We can also, for each topic, count the number of documents having it as a main topic.\n",
        "\n",
        "In the following, we will compute those 2 approaches."
      ],
      "metadata": {
        "id": "HYTMIxPHixL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First Approach\n",
        "topic_results_df = pd.DataFrame(topic_results)\n",
        "## We sum all the probabilities, sort the table, and get the first/last topic\n",
        "table = topic_results_df.apply(sum, axis = 0).argsort()\n",
        "main_topic_1 = table[topic_results.shape[1]-1]\n",
        "worst_topic_1 = table[0]"
      ],
      "metadata": {
        "id": "yTyrL2M73_m0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Second approach\n",
        "## We group documents depending on their main topic\n",
        "data_by_topic = link_topics.groupby('Main topic')\n",
        "number_questions_per_topic = np.zeros((topic_results.shape[1],1),dtype=int)\n",
        "\n",
        "## Iteratively, we compute, for each topic, the number of documents having it as main topic\n",
        "for key in list(data_by_topic.groups.keys()):\n",
        "    # We get the part of the data frame dedicated to the product being studied\n",
        "    data_topic = data_by_topic.get_group(key)\n",
        "    # We get the number of documents having this main topic\n",
        "    number_questions_per_topic[key] = len(data_topic)\n",
        "\n",
        "## Then, we sort the table, and select the first/last\n",
        "main_topic_2 = number_questions_per_topic[:,0].argsort()[topic_results.shape[1]-1]\n",
        "worst_topic_2 = number_questions_per_topic[:,0].argsort()[0]\n"
      ],
      "metadata": {
        "id": "zFElKb3v5cPe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"APPROACH 1 : \")\n",
        "print(\"     - Topic people are mostly interested in : TOPIC\",main_topic_1)\n",
        "print(\"     - Least interesting topic for people :    TOPIC\",worst_topic_1,\"\\n\")\n",
        "\n",
        "print(\"APPROACH 2 : \")\n",
        "print(\"     - Topic people are mostly interested in : TOPIC\",main_topic_2)\n",
        "print(\"     - Least interesting topic for people :    TOPIC\",worst_topic_2,\"\\n\")"
      ],
      "metadata": {
        "id": "HImYejj1783P",
        "outputId": "91e66ca5-401f-41bd-a404-0d2b6896639d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "APPROACH 1 : \n",
            "     - Topic people are mostly interested in : TOPIC 5\n",
            "     - Least interesting topic for people :    TOPIC 6 \n",
            "\n",
            "APPROACH 2 : \n",
            "     - Topic people are mostly interested in : TOPIC 5\n",
            "     - Least interesting topic for people :    TOPIC 6 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, in the end, our 2 approaches give the same result : according to our study, TOPIC 5 is the most interesting one, and TOPIC 6 is the least interesting."
      ],
      "metadata": {
        "id": "YDR3QT7zgEnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "During this 5th delivery, as we did last week, we have used the theoritical notions learnt in class to answer business problems.\n",
        "\n",
        "Re-using functions defined for the 4th delivery, and writing new ones, we achieved to answer the different questions, this time, for Quora."
      ],
      "metadata": {
        "id": "JBiidoCyoS0J"
      }
    }
  ]
}